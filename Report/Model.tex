\documentclass[a4paper,10pt]{article}
\title{Rhythmic structure in performed Jazz music}
\author{Bastiaan van der Weij}

\usepackage[round]{natbib}
\usepackage{graphicx}
\usepackage{amsmath}
%\usepackage{fullpage}

%\date{Augustus 17, 2012}


\begin{document}

\section{Method}
\label{sec:method}

\subsection{Chart Parsing/Statistical Longuet-Higgins}

\label{sec:chart}

We consider a rhythm to be a list of note onsets. We ignore note offsets, even though in many cases, note offsets are rhythmically timed as well, note onsets seem to be the most important property of rhythms and also the property that a rhythms played by any instruments has in common (it is hard for example to define the note offsets of a drum line). When note onsets form a rhythm, we can assume that there is a set of units, or metrical durations that form are the atomic units that the onset times are build off. These metrical durations are mostly constrained to be duple or triple divisions of each other. Other divisions are allowed as well but are far less common. When a metrical unit is divided into two or three units, the leftmost unit is, by convention, called the downbeat. The other unit(s) are called upbeat(s).

The task of finding rhythmic structure can now be defined as finding the appropriate atomic units and finding the location of the downbeats. When humans perform a rhythm, some information about this underlying structure is encoded in the performance of the rhythm which may be why humans find it usually easy to hear the downbeat. In many music styles, it is common to emphasise the downbeat. It is hypothesised here that this emphasis takes the form of a slight asymmetry in the duration of the downbeat and the duration of the upbeat.

A parser is presented here that forms hypotheses about the atomic units that make up a rhythm. The parser is essentially a stochastic CKY parser that combines hypotheses about note onsets. The parser uses a small set of rules and two constraints that restrict it to form only valid rhythmic structures. 

\begin{align*}
\label{eq:rules}
D(\textrm{combine}(h_1, h_2)) &\rightarrow D(h_1) D(h_2)\\
D(\textrm{combine}(h_1, h_2)) &\rightarrow D(h_1) D(h_2) D((h_3)\\
D(\textrm{h}) &\rightarrow \textrm{On}_i\\
D(\textrm{h}) &\rightarrow *
\end{align*}
where $D(\phi)$ is a metrical duration with features $\phi$, $*$ represents a filler duration (this is needed when notes are tied together or when the first note is not the first beat of a measure) [SHOW SOME EXAMPLES HERE], $\textrm{On}_i$ is an onset at index $i$, $h$ is an hypothesis about the rhythmic analysis of the corresponding metrical duration and $\textrm{combine}/2$ and $\textrm{combine}/3$ are functions that take hypotheses and combine them into a new hypothesis.

The two constraints are:
\begin{enumerate}
\item Any set of two or three metrical durations are not allowed to combine if the first one expands directly to an onset and the others do not recursively expand to an onset.
\item Any set of two or three metrical durations is not allowed to combine if none of the recursively contains an onset.
\end{enumerate}

The parser works like any other stochastic CKY parser where symbols are added to the chart only if their probability is higher than a certain threshold.

The performance of the parser is determined in the first place by how a onsets are translated into hypotheses and how hypotheses are combined and in the second place by how the probability of a certain hypothesis is determined. When the probability function would simply assign the probability 1.0 to each hypothesis, the parser would generate an infinite number of hypotheses. The following sections will introduce hypothesis generation and combination functions for inputs with metronomic timing.

\subsection{Metronomic onset hypothesis generation}

When we assume the onsets are metronomic, we can represent hypotheses in a compact and efficient format. Apart from metronomic onsets we need to make a few further assumptions: the parser can only come up with a valid analysis if we assume that (1) the time $t=0$ corresponds to the first beat of the time signature and that (2) there is an end marker which is placed at the $n$-th bar, where $n$ is the first power of two after the index of the last bar of the rhythm. For example, if we have a 3-bar rhythm, the end marker is placed at the first beat of the 4th bar.

Let us define the parser input as rhythm $R$, consisting of a list of onset-times, the last of which is not an onset but an end-marker. 

\begin{equation}
R_{0,n} = [\textrm{On}_0, \textrm{On}_{1}, \cdots, \textrm{On}_n]
\end{equation}

Before we can parse this rhythm we convert the rhythm $R_{0,n}$ to input $I_{0,n-1}$ (excluding the end marker at $R_n$). This conversion converts each onset to 3-tuple:

\begin{equation}
I_i = (R_{i-1}, R_i, R_{i+1}),
\end{equation}
containing the previous onset, the current onset and the next onset. At $I_0$, the previous onset is assumed to be $0$, at $I_{n-1}$ the next onset is $R_n$, which is the end-marker. 

An hypothesis is represented as a set of features associated with the corresponding duration symbol $D$. Each duration symbol will have at least two: the first onset in the symbol, $I_i$ and its position within the symbol. When a duration symbol contains more than one onset, a third feature is added that contains the length of the symbol that is implied by the onsets in the symbol.

\subsection{Expressive onset hypothesis generation}

When onsets are not guaranteed to be metronomic we need a different way of representing hypotheses. It is particularly important where we predict future onsets to be given what we have already seen.

For this we extend the duration symbol with three optional features. Every symbol now has a vector of onsets or ties. The first item of this vector is defined to be the downbeat, the rest are upbeats. The interval of the downbeat and the first upbeat at level $l$ is the downbeat interval at level $l+1$. This notion is the basis of the model. As soon as a vector contains more than one onset, the vector is filled in with expected onsets given the two onsets.
\subsection*{Probabilistic parsing}

A probabilistic model of rhythm can be formulated in a Bayesian way. 

\begin{equation}
\label{eq:model}
P(A|N) \propto P(N|A)P(A),
\end{equation}

where $A$ is a rhythmic analysis and $N$ is a list of onset times. The goal of the analysis is to find the analysis that maximises the formula above.

Equation \ref{eq:model} contains two factors: the likelihood of a note pattern given an analysis $P(N|A)$ and the prior probability of the note pattern $P(A)$. 

We would like to use our corpus to estimate both probabilities. The prior can be established using a simple PCFG. [Explain somewhere why a PCFG captures Temperley's properties of common practice rhythm.] The likelihood of an analysis is more complicated.

Most models use a tempo curve and a normal distribution that penalises deviation from metronomic tempo. Since we have structural information about the rhythm, like where downbeats are located and since this structural information likely correlates with certain expressive properties of rhythm. We may be able to use this to our advantage. 

Many models use tempo curves to determine

Other authors have suggested balancing simplicity and accuracy. We can now elaborate simplicity as the degree to which a rhythmic structure is similar to what we have seen in a corpus and accuracy as the degree to which the onsets generated by the structure are similar to what we would expect.

Many models consider the expressive timing to be Gaussian noise relative to the tempo curve. Since we have structural information we can see if there is a correlation between structure and expressive timing. Often, in such models, the prior is measured as the complexity of the score. Our analysis allows us to determine the likelihood of the rhythmic structure itself. 





%Longuet-Higgins used a constant tolerance parameter to determine whether a beat should be subdivided or a rest should be generated. Increased computational power and availability of labelled data now allows us to makes these decisions probabilistic.

%\begin{align*}
%&P(A \rightarrow B, C|O) = P(N|A \rightarrow B, C)P(A \rightarrow B, C)\\
%&P(A \rightarrow b|O) = P(N_i|A \rightarrow b)P(A \rightarrow b)
%\end{align*}

%where A, B, C are arbitrary non-terminal symbols, b is a terminal symbol and O is a set of observations. 

%The priors are given by for example a simple PCFG-like model, below we will only discuss likelihoods. Consider a bottom up chart-parsing algorithm. Such an algorithm would for example consider the (possibility that the first note in the following pattern was generated by the rule $B/4 \rightarrow n$, which is, in this case, correct. 

% Annotation issues
\bibliographystyle{plainnat}
\bibliography{refs}

\end{document}