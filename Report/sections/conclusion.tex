\chapter{Conclusion}
\label{sec:conclusion}

% Tempo invariant approach
% Tempo and time signature is/can be detected.
% Detection of tactus, meter and transcription integrated in one approach
% Rests are needed
% More data is needed for expression

We proposed a system that, in the first place, was aimed at interpreting rhythmic structure in performances. We proposed an approach that combines chart-parsing with a Bayesian model of rhythmic structures. This model consisted of a rhythm model and an expression model. The rhythm model was a probabilistic context-free grammar that assigned probabilities to context-free rule expansions of subdivision trees. Two expression models were proposed, both based on down-/upbeat length ratios. The expression-aware model could potentially learn expressive deviation biases, linked to rhythmic structure in performances, the alternative expression model treated expression, defined as down-/upbeat ratios non-equal to one, as noise.

Furthermore, we produced an annotated corpus of monophonic performances of jazz melodies. The performances are annotated with metrical onset times, time signatures, and rhythmic structure in terms of subdivision trees. Since there are few other corpora with this kind of information and, as far as we know, it is the first of its kind that focusses on jazz music, this corpus could potentially be useful in future studies in this field. 

At the moment our approach only covers time signatures with duple divisions and triple divisions, where triple divisions are restricted to the note level. More work is needed to extend the parser to allow other divisions and triple divisions at higher levels.

Our rhythm model became sensitive to some regularities in rhythms that have been suggested by \citet{temperley2010modeling} as common practice. This shows that our rhythm model is both an acceptable model of rhythm perception and that common practice rhythm principles generalise to some extent to rhythms jazz music.

We initially claimed that some local expressive deviations may be correlated with rhythmic structure, as observed by \citet{bengtsson1983analysis}. Our results, however, showed that the expression-aware model in its current form was not able to improve parser performance. In our discussion of the results we suggested that this was caused by a high amount of noise in the model, probably caused by the way we predict downbeat and next downbeat onsets. At this point, the expression model needs improvement.

Our alternative expression model, which treats expressive deviation as noise, did perform significantly better than the baseline and often produced correct rhythmic structures. We have argued that subdivision parsing is an elegant approach, since it makes no assumptions about tempo, and that for this reason it is particularly well-suited for studying expression. Our results show that a subdivision-based parser is indeed able to produce correct subdivision trees of expressively performed rhythms in jazz music.