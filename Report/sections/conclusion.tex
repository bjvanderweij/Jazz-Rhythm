\chapter{Conclusion}
\label{sec:conclusion}

% Tempo invariant approach
% Tempo and time signature is/can be detected.
% Detection of tactus, meter and transcription integrated in one approach
% Rests are needed
% More data is needed for expression

We proposed a system that in the first place was aimed at inferring rhythmic structure from performances. We proposed an approach that combines chart-parsing with a Bayesian model of rhythmic structures. This model consisted of a rhythm model and an expression model. The rhythm model was a probabilistic context-free grammar that assigned probabilities to context-free rule expansions of subdivision trees. The expression model was a generative model that can learn potential expressive deviation biases, linked to rhythmic structure in performances.

Furthermore, we produced an annotated corpus of monophonic performances of jazz melodies. The performances are annotated with metrical onset times, time signatures, and rhythmic structure in terms of subdivision trees. Since there are few other corpora with this kind of information and, as far as we know, it is the first of its kind that focusses on jazz music, this corpus could potentially be useful in future studies in this field. 

At the moment our approach only covers time signatures with duple divisions and triple divisions, where triple divisions are restricted to the note level. More work is needed to extend the parser to allow other divisions and triple divisions at higher levels.

Our rhythm model became sensitive to some regularities in rhythms that have been suggested by \citet{temperley2010modeling} as common-practice. This shows that our rhythm model is both an acceptable model of rhythm perception and that common practice rhythm principles generalise to some extent to rhythms jazz music.

We initially claimed that this model may be able to capture some expressive regularities linked to rhythmic structure as observed by \citet{bengtsson1983analysis}. Our evaluation showed that our model failed to use its expression model to its advantage. In our discussion of the results we have argued that this may be caused by the way we predict downbeat and next downbeat onsets. At this point, our model needs improvement.

We then simplified our expression model to treat expressive deviations as additive noise. Our results show that this approach works to some degree. We have argued tempo independent subdivision parsing is an elegant approach that is particularly well suited for studying expression. Although a more thorough evaluation is needed, our results show that the subdivision parsing is sometimes able to produce correct analyses of expressively performed jazz music.