\chapter{Conclusion}
\label{sec:conclusion}

% Tempo invariant approach
% Tempo and time signature is/can be detected.
% Detection of tactus, meter and transcription integrated in one approach
% Rests are needed
% More data is needed for expression

We proposed a system that in the first place was aimed at inferring rhythmic structure from performances. We proposed an approach that combines chart-parsing with a Bayesian model of rhythmic structures. This model consisted of a rhythm model and an expression model. The rhythm model was a probabilistic context-free grammar that assigned probabilities to context-free rule expansions of subdivision trees. The expression model was a generative model that can learn potential expressive deviation biases, linked to rhythmic structure in performances.

Furthermore, we produced an annotated corpus of monophonic performances of jazz melodies. The performances are annotated with metrical onset times, time signatures, and rhythmic structure in terms of subdivision trees. For there are few other corpora with this kind of information and as far as we know, it is the first of its kind that focusses on jazz music, this corpus could potentially be useful in future studies in this field. 

Our rhythm model became sensitive to some regularities in rhythms that have been suggested by \citet{temperley2010modeling} as common-practice. This shows that our rhythm model is both an acceptable model of rhythm perception and that common practice rhythm principles generalise to some extent to rhythms jazz music.

At the moment our approach only covers time signatures with duple divisions and triple divisions, where triple divisions are restricted to the note level. More work is needed to extend the parser to allow other divisions and triple divisions at higher levels.

We initially claimed that this model may be able to capture some expressive regularities linked to rhythmic structure as observed by \citet{bengtsson1983analysis}. Our evaluation showed that our model failed to use its expression model to its advantage. In our discussion of the results we have argued that this failure may be to blame on methodological issues.

We then simplified our expression model to treat expressive deviations as additive noise. Our results show that this approach works to some degree. We have argued that a subdivision representation is elegant as it is free of tempo curves or any tempo-related parameters. Only when we want to generate scores from our analyses, a model containing tempo-related parameters may be necessary.

In any case, the question whether expressive regularities linked to rhythmic structure can help improve rhythmic parsing remains unanswered. 
