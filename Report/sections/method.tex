\chapter{Method}
\label{sec:method}


\section{Background}

We assume that we can represent the performance $P$, of a rhythm as series of note onset times. 
\begin{equation}
\label{eq:performance}
P = [\mathrm{On}_0, \mathrm{On}_1, \cdots, \mathrm{On}_n]
\end{equation}
where $\mathrm{On}_i$ is a note onset. For human listeners, this information is usually enough to correctly identify the rhythmic structure. Other features of the perception, like pitch and note offsets are useful as well, but in many cases, note onsets are sufficient. Note onsets are also the property that rhythms played by any instruments have in common. When a rhythm is performed on a drum for example, pitch and note offsets are practically absent.

We will consider the perceived \textit{rhythm} to be the underlying structure of a performance and the performance a noisy representation of the underlying rhythm. In Western music tradition, a rhythm can be described as a series of subdivision of some metrical unit. The most common subdivisions are duple and triple divisions. Other prime number divisions are allowed as well but are far less common in at least in Western music tradition. When a metrical unit is divided into two or three units, the leftmost unit is, by convention, called the \textit{downbeat}. The other unit(s) are called \textit{upbeat}(s).

A quarter note in a 4/4 time signature for example, is a whole note divided two twice. The first beat of a 4/4 bar is the downbeat at the half note level and every level below. The third beat of the bar is an upbeat at the half note level, since its the second half of a whole note divided by two, but a downbeat at the quarter note level and below. Many authors have used the notion of a metrical grid, introduced by \citet{lerdahl1983generative} in their Generative Theory of Tonal Music, to represent this structure. Another popular representation of rhythmic structure is staff notation. Here we will use a different kind of representation which we will refer to as \textit{subdivision trees}. We will argue that this is a more general representation of rhythm than staff notation or metrical grids. [No timesignatures, irrelevance of tempo curves]

Every node in the subdivision tree represents a metrical duration. Any node can be subdivided into any prime number of subnodes. A node is considered to be non-terminal if it is subdivided and terminal if it is not. There are two types of terminal nodes: an onset, which we will show as $\bullet$ in our graphical representation of trees, and a filler unit, which will be shown as $*$. A filler unit can be either a tied note or a rest. There are no rests in the subdivision trees since we are only looking at onsets. The filler units will be referred to as ties from now on.

The metrical length of a node's child nodes is equal to the length of the node divided by the number of children. We do not need to define the length of the root node, and therefore metrical durations can be expressed relatively as a number of divisions of the root node. We can make a distinction between a \textit{metronomic duration} and a \textit{metrical duration}. Where a metronomic duration is a duration measured in some unit of time and a metrical duration is a duration relative to the root node. 

An example of a well known rhythmic clich\'e and its analysis is shown in figure \ref{fig:subdivision:a} to illustrate the concept of a subdivision tree. The root note is labelled 1/1,  its children are labelled 1/2, etc. These fractions are fractions of the duration of the whole rhythm and are not to be confused with actual whole notes and half notes, which are a consequence of the time signature. They simply are subdivisions of the total length of the rhythm. In order to derive a score from the tree in figure \ref{fig:subdivision:a}, we need to assign some level in the tree to equal a whole bar. Score A in figure \ref{fig:subdivision:b} shows how the first note becomes an eighth note under a 4/4 time signature with the bar duration set to to the root node. Setting the bar duration one level lower results in score B and setting another level lower results in score C. Hence, a subdivision tree abstracts away time signatures, making it a more general representation than staff notation.

\begin{figure}
\centering
\subfloat[]{
\label{fig:subdivision:a}
\centering
\Tree
[ .{$\frac{1}{1}$} [ .{$\frac{1}{2}$} [ .{$\frac{1}{4}$} [ .$\bullet$ ] [ .{$\frac{1}{8}$} [ .$\bullet$ ] [ .$\bullet$ ] [ .$\bullet$ ] ] ] [ .{$\frac{1}{4}$} [ .$\bullet$ ] [ .$\bullet$ ] ] ] [ .{$\frac{1}{2}$} [ .{$\frac{1}{4}$} [ .$*$ ] [ .$\bullet$ ] ] [ .$\bullet$ ] ] ] 
}

\subfloat[]{
\label{fig:subdivision:b}
\centering
\begin{tabular}{| l  >{\centering\arraybackslash}m{2in} |}
\hline 
A & \includegraphics[scale=0.3]{img/subdivision_score1}\\
B & \includegraphics[scale=0.3]{img/subdivision_score2}\\
C & \includegraphics[scale=0.3]{img/subdivision_score3}\\
\hline
\end{tabular}
}
\caption{An analysis and three different score notations of the same musical clich\'e. }
\label{fig:subdivision}
\end{figure}

%When humans perform a rhythm, some information about this underlying structure is encoded in the performance of the rhythm which may be why humans find it usually easy to hear the downbeat. In many music styles, it is common to emphasise the downbeat. It is hypothesised here that this emphasis takes the form of a slight asymmetry in the duration of the downbeat and the duration of the upbeat.

\section{Parsing Rhythms}

The approach presented here generates the most likely rhythmic structure $R$ underlying a performance $P$, where $R$ is a subdivision tree as described in the previous section and $P$ is a list of onsets as shown in equation \ref{eq:performance}. During this process the parser considers all possible hypotheses of small sub spans of $P$ and retains the most likely ones. This is feasible because we assume that over a few notes, only a small number of hypotheses are worth considering. In this section we will first describe how rhythmic analyses that are structurally sound are generated. After that, we will outline a Bayesian model that defines how we determine whether a hypothesis is likely.

The process of generating hypotheses about performances will be referred to as parsing from now on. Rhythmic analyses will be generated by a slightly modified stochastic CKY chart parser [Reference]. The algorithm and modifications are explained in appendix \ref{app:parser}. A small context-free grammar augmented with some constraints can be used to generate subdivision trees. The grammar that is used in this study is given below.  Notably, only duple and triple divisions are allowed by this grammar. In this study only these subdivisions will be considered.
\begin{align}
R &\rightarrow R\: R\\ \notag
R &\rightarrow R\: R\: R\\ \notag
R &\rightarrow \bullet\\ \notag
R &\rightarrow * \notag
\end{align}
where $R$ is a subdivision tree, $*$ represents a tie, $\bullet$ is an onset. 

The CKY parser only accepts grammars that are in Chomsky normal form (CNF). That is, all rules should be of the form $A \rightarrow B, C$ or $A \rightarrow \alpha$, where $A$, $B$ and $C$ are non-terminal symbols and $\alpha$ is a terminal symbol. Converting the grammar above to (CNF) results in the following grammar:
\begin{align}
\label{eq:grammar_cnf}
R &\rightarrow R\: R,\\ \notag
R &\rightarrow R\: R',\\ \notag
R' &\rightarrow R\: R,\\ \notag
R &\rightarrow \bullet,\\ \notag
R &\rightarrow *. \notag
\end{align}

Two constraints are needed to prevent the parser from generating invalid rhythmical structures. These constraints are: (1) Any set of two or three metrical durations are not allowed to combine if the first one expands directly to an onset and the others do not recursively expand to an onset. (2) Any metrical durations is not allowed to combine if none of them recursively contains an onset.

The first constraint prevents the parser from generating structures with an onset on the downbeat and a tie on the upbeat. Tying a downbeat to an upbeat would not make sense since a quarter note tied to a quarter note is simply a half note. The second constraint prevents the parser from combining subdivision trees that do not contain onsets.

% Explanation of the chart parser?

This completely defines the parser. At this point however, the parser simply generates all possible interpretations of an onset list of a certain length. The next sections will describe how a probabilistic model is used to reject unlikely interpretations and retain the likely ones.

\section{Hypothesis generation and rejection}
\label{sec:rejection}

Subdivision trees generated by the parser can be seen as hypotheses about the rhythmic structure (some sub-span of) the performance. We will assume that the likelihood of an hypotheses given a set of performed onsets is determined by two factors: One is how well the analysis matches the observed onset times and another is likely the rhythm itself is. [Picture of too detailed versus too simple analyses a la cemgil 2000]. In other words, we want to find the \textit{posterior} probability $P(A|N)$, where $A$ is a rhythm, and $N$ is a list of note onsets. We can formulate this as a generative model where
\begin{equation}
\label{eq:model}
P(R|P) \propto P(P|R)P(R).
\end{equation}

The posterior probability $P(R|P)$ of a rhythm $R$ given a performance $P$ is proportional to the probability that $R$ generated performance $P$, $P(P|R)$, times the probability of $R$ itself, $P(R)$. $P(P|R)$ will be referred to as the \textit{likelihood} of $R$ given $P$ and $P(R)$ will be referred to as the \textit{prior} probability of $R$.

The chart parser should only keep track of reasonably sensible hypotheses in its chart. The Bayesian model above allows us to define a sensible hypothesis as a hypothesis that has a high posterior probability. 

The following sections will deal with the representation of hypotheses about onsets and estimating the likelihood of such hypotheses given a performance. 

\section{Hypothesis likelihood}
\subsection{Representation}
\label{sec:hypothesis_representation}

\begin{figure}
\Tree
[ .{$\frac{1}{1}$} [ .{$\frac{1}{2}$} [ .$\bullet$ ] [ .$\bullet$ ] ] [ .$*$ ] ]
\caption{A rhythmic analysis, which can be represented as the nested list $((\bullet, \bullet), *)$.}
\label{fig:smalltree}
\end{figure}

While a subdivision tree specifies a rhythmic structure, it does not keep track of the onsets associated with the structure. In order to be able to say anything about the likelihood of an analysis, we need to have information about the onsets it contains. Therefore we will introduce a distinction between a rhythmic analysis $R$, produced by the grammar in (\ref{eq:grammar_cnf}) and a \textit{hypothesis} $h$. 

A subdivision tree is essentially a syntax tree, which, as any syntax tree, can be represented as a nested list. The tree in figure \ref{fig:smalltree} for example, can also be written as $((\bullet, \bullet), *)$. Hypotheses have a similar structure but also keep track of onsets on on the down- and upbeats. The 3-tuple below completely specifies a hypothesis.
\begin{equation}
h = (H, B, O)
\end{equation}
where $H$ is a list of nested hypotheses and $B$ is a list of predicted down- and upbeats that will be constructed using the \textsc{combine} function introduced later in this section. $O$ is a list of actual onsets and may contain $*$ symbols when no onsets are present at some positions. Both $B$ and $O$ only contain onsets on the level of the hypothesis, that is, they contain the down- and upbeat(s) of the hypothesis and their length is always the same as the amount of units the hypothesis divides in. 

A single onset is represented as a hypothesis with zero nested hypotheses: $(\emptyset, [\textrm{On}_i], [\textrm{On}_i])$, where $\textrm{On}_i$ is an absolute onset time at position $i$ in some performance $P$. Similarly, a single tie is represented as: $(\emptyset, [*], [*])$. Combining these hypotheses yields $([(\emptyset, [*], *), (\emptyset, [\textrm{On}_i], \textrm{On}_i)], [*, On_i], [*, On_i])$. Both the list of predicted beats $B$ and the list of onsets $O$ contain the $*$ symbol here. When this hypothesis combines with other onsets, the \textsc{combine} function will fill in the estimated onsets of $*$ in the list of beats $B$, but not in the list of onsets $O$. When the \textsc{observations} function is introduced in section \ref{sec:observations} it will become clear why the list of onsets $O$ is needed.

\subsection{Combination}
\label{sec:combination}

Estimating the likelihood of a hypothesis is done in a two-step process. The first step is a bottom-up process where the down- and upbeats of every hypothesis is estimated. The second step is a top down process that generates a list of observations given a hypothesis. The likelihood of these observations can be determined after training the model on a corpus.

A hypothesis is said to \textit{govern} a set of onsets if the hypothesis recursively contains these onsets. The \textsc{combine} function cannot estimate down- and upbeats when of a hypothesis that only governs a single onset. Such hypotheses are treated as a \textit{complex onset}. The hypothesis in figure \ref{fig:complexonsets:a} for example is treated as an onset at relative position $0.5$, the hypothesis in figure \ref{fig:complexonsets:b} is treated as an onset with relative position $0.75$.

\begin{figure}
\centering
\subfloat[complex onset: $0.5$]{
\label{fig:complexonsets:a}
\parbox{4cm}{\centering
\Tree
[ .{$\frac{1}{1}$} [ .$*$ ] [ .$\bullet$ ] ] 
}
}
\subfloat[complex onset: $0.75$]{
\label{fig:complexonsets:b}
\parbox{4cm}{\centering
\Tree
[ .{$\frac{1}{1}$} [ .$*$ ] [ .{$\frac{1}{2}$} [ .$*$ ] [ .$\bullet$ ] ] ] 
}
}
\caption{Complex onsets (single-onset analyses).}
\label{fig:complexonsets}
\end{figure}

The goal of the \textsc{combine} function is to get the best possible estimates of where the up and downbeats of a hypothesis are. The algorithm works roughly as follows. The input is a list $H$ containing two or three hypotheses. These will be the child nodes of the hypothesis that the combine function is building. The algorithm iterates through the list of hypotheses. If a hypothesis is an onset, the position of the onset and the absolute onset are added to \textit{onsets}. The position is a number between 0 and 2 or 0 and 3, depending on the number of hypotheses in $H$. If a hypothesis is a complex onset, its complex position, determined by the function \textsc{complexPostion}, and absolute onset are added to \textit{complexOnsets}. If a hypothesis suggests a downbeat, this downbeat and its position are added to \textit{onsets}.

\begin{algorithm}
\caption{Combine hypotheses}
\label{alg:combination}
\begin{algorithmic}
\Function{combine}{$H$}
	\State $d \leftarrow$ \Call{length}{$H$}
	\State onsets $\leftarrow \emptyset$
	\State complexOnsets $\leftarrow \emptyset$
	\For{$i \leftarrow 0,d$}
		\State $(H', B', O') \leftarrow H[i]$
		\If{$H' = \emptyset$ \textbf{and} $B \neq [*]$}
			\State \textbf{append} ($i, H'[i]$) \textbf{to} onsets
		\Else
			\If{$B'[0] \neq *$}
				\State \textbf{append} $(i, B'[0])$ \textbf{to} onsets
			\If{$O'[0] \neq *$}
				\State \textbf{append} $(i, O'[0])$ \textbf{to} $O$
			\EndIf
			\Else
				\State $p$, complexOnset $\leftarrow$ \Call{complexPosition}{$H'[i]$}
				\State \textbf{append} ($i + p$, complexOnset) \textbf{to} complexOnsets
			\EndIf
		\EndIf
	\EndFor
	\If{\Call{length}{onsets} $\leq 1$}
		\State \textbf{append} complexOnsets \textbf{to} onsets
	\EndIf
	\State $B \leftarrow$ \Call{fill}{onsets, $d$}
	\State \textbf{return} $(H, B, O)$
\EndFunction
\end{algorithmic}
\end{algorithm}

Once the algorithm has iterated thought $H$, the algorithm checks whether there is an onset on the downbeat. If there is not, the \textsc{downbeat} function attempts to estimate the downbeat from the list of onsets. We assume that an interval based on one or more complex positions is less reliable than an interval based on intervals between downbeats. Only if \textit{onsets} contains less than two onsets, \textit{complexOnsets} is added to it. When the combined length of \textit{onsets} and \textit{complexOnsets} is 1, this hypothesis governs only one onset and the list of beats will only contain that onset and one or more ties. If the combined \textit{onsets} and \textit{complexOnsets} contains more than one onset, the \textsc{downbeat} function estimates downbeat from these onsets.

In a practical implementation, every hypothesis should also keep track of the first onset before and after the hypothesis. This can be used later to restrict endlessly adding ties to the hypothesis. [More explanation]

\subsection{Generating observations}
\label{sec:observations}

The combination process combines hypotheses makes sure that every hypothesis governing more than one note contains an estimated downbeat. This information is used by the \textsc{observations} function, which estimates how much observed onsets deviate from the onsets implied by the rhythmic structure. The \textsc{observations} function takes a hypothesis $h$ as input and transforms it to a list of observations with feature vectors. Here, we define an observation to be the logarithmic ratio of the observed upbeat and downbeat length. In a metronomic performance, we expect a down- and upbeats to be of the same length and their logarithmic ratio to be zero. In our model, we will try to estimate learn a mapping between between a feature vector and a logarithmic down-/upbeat ratio.

Given a downbeat interval, an onset and its relative

The observation function is a top-down recursive function. It calculates the expected onset of every down- and upbeat of every hypothesis in the tree. The main assumption of the function is that the expected onsets of the upbeats at level some are derived from the downbeat interval at the level above. 

For a hypothesis $h = (C, N, b_d)$, the algorithm is initialised as follows: $\textsc{observations}(h, b_d, *, \textsc{length}(C) \times (N[1] - b_d))$, where $\textsc{length}(C) \times (N[1] - b_d)$ is the division times the length interval of the downbeat and the first upbeat.
\begin{algorithm}
\caption{Generate observations}
\label{alg:observations}
\begin{algorithmic}
\Function{observations}{$h$, downbeat, nextDownbeat}
	\State $H, B, O \leftarrow h$
	\If {$B[0] \neq *$}
		\State downbeat $\leftarrow B[0]$
	\EndIf
	\State \textbf{append} * \textbf{to} $O$
	\State $d \leftarrow$ \Call{length}{$C$}
	\State $l \leftarrow$ nextDownbeat - downbeat
	\State $\Phi \leftarrow \emptyset$

	\For {$i \leftarrow 1,d$}
		\If {$B[i] \neq *$ \textbf{and} $i \neq 0$}
			\State \textbf{append} \Call{$\phi$}{downbeat, nextDownbeat, $B[i]$, $i$, $d$} \textbf{to} $\Phi$
		\EndIf	
		\State $H', B', O' \leftarrow H[i]$
		\If {$H' \neq \emptyset$}
			\State $b_{\mathrm{down}} \leftarrow \mathrm{downbeat} + l * i/d$
			\If {$B[i] \neq *$}
				\State $b_{\mathrm{down}} \leftarrow B[i]$
			\EndIf
			\State $b_{\mathrm{up}} \leftarrow b_{\mathrm{down}} + l/d$
			\State $b_{\mathrm{up}} \leftarrow O[i+1]$
			\State \textbf{append} \Call{observations}{$(H', B', O'), b_{\mathrm{down}}, b_{\mathrm{up}}$} \textbf{to} O
		\EndIf
	\EndFor
	\State \textbf{return} $\Phi$
\EndFunction
\end{algorithmic}
\end{algorithm}

Given an expected and observed onset

\begin{equation}
\Phi(\beta, \beta', b, i, d) = \frac{(b - \beta) / i}{(\beta' - b) / (d - i)},
\end{equation}
where $\beta$ is a downbeat, $\beta'$ is the next downbeat, $b$ is an onset, $i$ is the position of $b$, and $d$ is the number of beats between $\beta$ and $\beta'$ (the division).

\subsection{Observation likelihood}
\label{sec:likelihood}

We can now calculate the likelihood of any hypothesis by taking the product of the observations that it implies. Optionally we can add an expression parameter that suggests the ratios to be slightly larger than one. The (normalised) likelihood of a set of observations is

\begin{equation}
\label{eq:h_likelihood}
\mathcal{L}(O|h, \mu, \sigma) \propto \prod_{i=0}^N \exp\left(-\frac{(\mu - \log(O_i))^2}{2\sigma^2}\right)
\end{equation}

Where $O$ is a set of down-/upbeat ratios. We expect the down-/upbeat ratios to be close to one and their to be logarithm close to zero. Therefore it makes sense to set $\mu$ to zero. However we may expect downbeats to be slightly stretched and we can set $\mu$ to reflect this.

Rejecting hypotheses

A hypothesis is rejected if the per item likelihood is lower than a certain threshold. The per-observation likelihood is defined as

\begin{equation}
\label{eq:per_obs_likelihood}
\mathcal{L}(O|h, \mu, \sigma) \mbox{ per observation } \propto \exp\left(-\frac{1}{N}\sum_{i=0}^N \frac{(\mu - \log(O_i))^2}{2\sigma^2}\right)
\end{equation}


%Constraints of the corpusparser (a parser that only allows metronomic performances)

%Single note analysis constraints

%Constraint in adding ties


%Introducing triple divisions introduces ambiguities between triple divisions or more complicated constructions of duple divisions (that are quite unlikely).

%For this we extend the duration symbol with three optional features. Every symbol now has a vector of onsets or ties. The first item of this vector is defined to be the downbeat, the rest are upbeats. The interval of the downbeat and the first upbeat at level $l$ is the downbeat interval at level $l+1$. This notion is the basis of the model. As soon as a vector contains more than one onset, the vector is filled in with expected onsets given the two onsets.

\section{Rhythm prior}

The prior should be an indication of how likely a rhythmic analysis is a priori. If the likelihood would be the only indication of the quality of an analysis, the analysis would become too detailed like in figure \ref{fig:detailed}. A prior is needed to prefer sensible analyses and reject over complicated ones. In addition to that, without a prior, the model would have no way of determining the phase (the location of the downbeats). [give example of equally likely analyses with different phases but more unlikely priors]

The prior used in this study is simply a probabilistic context-free grammar (PCFG). Usually, a PCFG assigns probabilities to the expanding of a non-terminal symbol to other non-terminal symbols. In our case, probabilities of non-terminal symbols to terminal symbols are included as well since there are only two terminal symbols.

The only non-terminal symbol in our grammar is a hypothesis that has child nodes. There are two terminal symbols: an onset and a tie. Since there is only one non-terminal in the grammar, the probability that a hypothesis $h$ expands to child nodes $C$ is given by

\begin{equation}
P((C, N, b_d) \rightarrow C) = P((C, N, b_d)) = \frac{\mathrm{count}((C, N, b_d))}{N},
\end{equation}
where N is the total number of non-terminal symbols.

\section{Data Preparation}

The parser's likelihood function takes two parameters: an expected logarithmic down-/upbeat ratio and its standard deviation. To estimate these values, a corpus of amateur jazz performances was prepared.

The corpus contains Jazz and Latin standards that were scraped off the the web [Cite Mark GW?]. The performances are generally of good quality and are played in a relatively constant tempo. In its original form, the corpus was a set of multi-track MIDI files containing both tracks played by a human performer and tracks generated by a computer in metronomic time.

MIDI files represent music as a list of note-on and note-off events, corresponding to key presses and key releases. Every event has the parameters pitch, velocity and delta-time. Delta-time specifies the time between this events and the last one, pitch is the pitch of the key that was pressed, velocity is the velocity with which the key was pressed or released.

For our purposes we want to have monophonic melody tracks played by a human performer. To get these tracks, every file in the corpus was split into separate tracks. Monophonic tracks played by humans were filtered out automatically. This was done by assuming that tracks played by humans contained a lot of variation in onset velocity and in inter-onset intervals due to imperfect timing. From this subset of performed tracks, tracks containing melodies where selected by hand. 

After the filtering process, [N-CORPUS] tracks were left containing melodies of [N-STANDARDS] different standards. These MIDI files where converted to note lists of the following format

\begin{align*}
N &= \{n_0, n_1, \cdots, n_N\},\\
n_i &= (\mathrm{On}_i, \mathrm{Pitch}_i, \mathrm{Velocity}_i),
\end{align*}
where $N$ is a note list containing notes $n_0$ to $n_N$, $\mathrm{On}_i$, $\mathrm{Pitch}_i$ and $\mathrm{Velocity}_i$ is the onset time in micro seconds, pitch and velocity of the $i^{\mathrm{th}}$ note. A very simple annotation format was chosen: every note in the note list was annotated with its metrical position, measured in quarter notes. 

Most of the corpus was played in swing, were it is common to play upbeat eighth notes as slightly delayed so that they fall on the third note of a eigth note triple, in terms of subdivision, the third beat of a quarter note divided by three. The example in figure \ref{fig:swing:a} shows a rhythm with some upbeat eighth notes. When performed in swing, the performance is usually closer to figure \ref{fig:swing:b}.

Although we now have metrical onsets, we still do not have the subdivision trees for the corpus. A simple parser with a flat prior and likelihood function that only allowed metronomic timing was used to generate parses for every item in the corpus. From these results correct parses where selected by hand. A subdivision tree for the swing example is shown in figure \ref{fig:swing:c}.


\begin{figure}
\centering
\subfloat[Rhythm notation]{
\label{fig:swing:a}
\centering
\includegraphics[scale=0.3]{img/aint_misbehavin}
}
\\
\subfloat[Annotation]{
\label{fig:swing:b}
\centering
\includegraphics[scale=0.3]{img/aint_misbehavin_swung}
}
\\
\subfloat[Parsetree]{
\label{fig:swing:c}
\centering
\Tree 
[ .{$\frac{1}{1}$} [ .{$\frac{1}{2}$} [ .{$\frac{1}{4}$} [ .$*$ ] [ .$*$ ] [ .$\bullet$ ] ] [ .{$\frac{1}{4}$} [ .$\bullet$ ] [ .$*$ ] [ .$\bullet$ ] ] ] [ .{$\frac{1}{2}$} [ .{$\frac{1}{4}$} [ .$\bullet$ ] [ .$*$ ] [ .$\bullet$ ] ] [ .$*$ ] ] ]
}
\caption{Annotation of swung notes.}
\end{figure}

The result of this process for Thelonious Monk's standard Blue Monk is shown in table \ref{tab:annotation}.

\begin{table}
\caption{A performance $P$, its metrical onsets, its rhythmic analysis and a score generated from this analysis.}
\label{tab:annotation}
\begin{tabular}{|l|}
\hline

\parbox{\linewidth}{
The performance onsets in milliseconds.
}\\

$P = [32, 348, 504, 836, 1940, 2240, 2420, 2728]$\\

\hline

\parbox{\linewidth}{
Metrical onsets in quarter notes. Triple divisions are rounded to two digits.
}\\

$ A = [0.0, 0.66, 1.0, 1.66, 4.0, 4.66, 5.0, 5.66]$\\

\hline

\parbox{\linewidth}{
Rhythmic analysis generated by a simple parser and selected by hand.
}\\

\Tree
[ .{$\frac{1}{1}$} [ .{$\frac{1}{2}$} [ .{$\frac{1}{4}$} [ .{$\frac{1}{8}$} [ .$\bullet$ ] [ .$*$ ] [ .$\bullet$ ] ] [ .{$\frac{1}{8}$} [ .$\bullet$ ] [ .$*$ ] [ .$\bullet$ ] ] ] [ .$*$ ] ] [ .{$\frac{1}{2}$} [ .{$\frac{1}{4}$} [ .{$\frac{1}{8}$} [ .$\bullet$ ] [ .$*$ ] [ .$\bullet$ ] ] [ .{$\frac{1}{8}$} [ .$\bullet$ ] [ .$*$ ] [ .$\bullet$ ] ] ] [ .$*$ ] ] ]
\\

\hline

\parbox{\linewidth}{
Score generated from the subdivision tree combined with pitch information. The bar duration was set to level 1/2 of the subdivision tree.}\\

\includegraphics[scale=0.4]{img/blue_monk}\\

\hline
\end{tabular}
\end{table}


\section{Training}

\subsection{Prior}



\subsection{Expression model}

$\mu$ and $\sigma$ for the bottom 4 levels?


\section{Parser optimisations}

To make the parser computationally tractable, a few optimisations were needed. It was already mentioned that the parser uses a beam parameter to reject unlikely hypotheses. In addition to that a few extra measures had to be taken.

First of all, the \textsc{observations} function returns no observations for hypotheses containing a single onset (complex onsets). Their probability is always one and theoretically ties could be added endlessly. To restrict this the parser maintains a small list of allowed single note analyses. This list is compiled by taking all single-note analyses found in the labelled corpus.

Second of all, the corpus contains only 4/4 time signatures, therefore triple divisions are allowed only at note level. All allowed triple divisions are shown in figure \ref{fig:triples}. 

\begin{figure}
$\bullet$
\Tree
[ .{$\frac{1}{1}$} [ .$*$ ] [ .$\bullet$ ] ] 
\Tree
[ .{$\frac{1}{1}$} [ .$*$ ] [ .$*$ ] [ .$\bullet$ ] ] 
\Tree
[ .{$\frac{1}{1}$} [ .$*$ ] [ .{$\frac{1}{2}$} [ .$*$ ] [ .$\bullet$ ] ] ] 
\Tree
[ .{$\frac{1}{1}$} [ .$*$ ] [ .{$\frac{1}{2}$} [ .{$\frac{1}{4}$} [ .$*$ ] [ .$\bullet$ ] ] [ .$*$ ] ] ] 
\caption{Some of the allowed single-note analyses.}
\label{fig:singlenotes}
\end{figure}

\begin{figure}
\Tree
[ .{$\frac{1}{1}$} [ .$*$ ] [ .$*$ ] [ .$\bullet$ ] ] 
\Tree
[ .{$\frac{1}{1}$} [ .$\bullet$ ] [ .$*$ ] [ .$\bullet$ ] ]
\Tree 
[ .{$\frac{1}{1}$} [ .$\bullet$ ] [ .$\bullet$ ] [ .$\bullet$ ] ]
\caption{Allowed triple divisions.}
\label{fig:triples}
\end{figure}

Third of all, the parser may at some point generate a large number of hypotheses due to ambiguities in the input. We do not need to keep track of all those hypotheses because the prior is able to select the most likely ones. The parser therefore only includes the best-$n$ hypotheses in every cell, where hypotheses are ranked by their posterior probability.
% Beam
% Triple divisions
% Best-n
% Max depth
%

\section{Overview}

% Chart parsing, beam, prior, likelihood, 
