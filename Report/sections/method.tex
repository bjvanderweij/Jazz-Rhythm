\section{Method}
\label{sec:method}

\subsection{Data preparation}

Jazz and Latin standards. Scraped from the internet. Performances of varying quality. Exclusively monophonic melody tracks. Melody tracks were performed on midi instruments. They were assigned to be played with different instruments including piano, saxophone and trumpet. All the melodies are played assumed to be played by humans with the help of a metronome. The constraints to determine human performances where that the performance should have have a minimum variation in time differences between note onsets and a minimum variation in velocities with which the notes were played.

Every note in the performance is annotated with its position, measured in quarter notes. Special elements are inserted for rests and grace notes. Grace notes are annotated assigned the same position as the notes they belongs to. Annotation was done using scores from various real books. Expression and deviation from these scores was made explicit in the annotations as much as possible; if three quarter notes are played as a triplet, they are annotated as a triplet. When the metrical positions of notes in the performance are unclear the annotations follow the score. Rests are inserted as notated in the score. The end of the annotations is marked by an end marker

The metrical length of a note can be derived by subtracting its metrical position from the metrical position of the next element in the annotations. The onset time of a rest is can be derived by multiplying the local 

\[A = \{a_0, a_1, \cdots, a_N\}\]
\[N = \{n_0, n_1, \cdots, n_N\}\]
\[a_i = (\mathrm{Beat}_i, \mathrm{Pointer}_i, \mathrm{Type}_i)\]
\[n_i = (\mathrm{On}_i, \mathrm{Off}_i, \mathrm{Pitch}_i, \mathrm{Velocity}_i)\]


Possible models include:
\begin{itemize}
\item Temperley's unified probabilistic model for polyphonic music analysis
\item Temperley's common-practice rhythm models
\item Potential other models in the literature
\item A CKY-like parsing algorithm 
\item Any other approach that includes performance information
\end{itemize}

Corpora:
\begin{itemize}
\item Essen folk (Used in common-practice rhythm)
\item Kostka-Payne (Used in UPMPMA
\item Jazz corpus (my own)
\end{itemize}


\subsection{Parsing Rhythms}

We consider the observation of a rhythm to be a of note onset times. In our system, note offsets are ignored. Although note offsets are rhythmically timed as well in many cases, note onsets seem to be the most important property of rhythms and also the property that rhythms played by any instruments have in common (it is hard for example to define the note offsets of a drum line). When note onsets are perceived as a rhythm, we assume that the perceived rhythm is an underlying structure. This structure defines a set of units, or metrical durations that form are the atomic units of the rhythm. These units are constrained to be duple or triple divisions of each other. Other prime number divisions are allowed as well but are far less common in Western music tradition. When a metrical unit is divided into two or three units, the leftmost unit is, by convention, called the downbeat. The other unit(s) are called upbeat(s).

A list of note onsets performed by a human is a noisy representation of the underlying structure. Some of this noise is caused by imperfection in the performance, some of the noise is caused by conscious deviation from the metronomic beat, otherwise known as expression.

The task of finding rhythmic structure can now be defined as finding the appropriate atomic units and finding the location of the downbeats. A structural representation of the rhythm should capture this information. Traditional staff notation is one possible structure that defines the location of downbeats and the atomic units that the onsets are build of. Instead of staff notation.

Every node in the subdivision tree represents a metrical duration. There are two types of terminals: an onset and a filler unit. A filler unit can be either a tied note or a rest. Since we are only looking at note onsets it does not make sense to distinguish tied notes from rests. The filler units will be referred to as ties from now on.

A node can be subdivided into any prime number of child nodes, although in this text we will assume that only duple and triple divisions are allowed. The metrical length of a node's child nodes is equal to the length of the node divided by the number of children. We do not need to define the length of the root node, and therefore metrical durations can be expressed relatively as a number of divisions of the root node. We can make a distinction between a \textit{metronomic duration} and a \textit{metrical duration}. Where a metronomic duration is a duration measured in some unit of time and a metrical duration is a duration relative to the root node. 

When humans perform a rhythm, some information about this underlying structure is encoded in the performance of the rhythm which may be why humans find it usually easy to hear the downbeat. In many music styles, it is common to emphasise the downbeat. It is hypothesised here that this emphasis takes the form of a slight asymmetry in the duration of the downbeat and the duration of the upbeat.

\subsubsection*{Parser}

The goal rhythmic parsing is find a number of hypotheses about the underlying rhythmic structure of a list of note onsets. An hypothesis is formulated as a structural analysis, or subdivision tree. We assume that over a few notes, only a small number of hypotheses are likely. First, we present a parser that considers all possible hypotheses of a number of note onsets. After that, we present a method to select likely hypotheses and reject unlikely hypotheses. 

The parser is essentially a stochastic CKY parser that combines hypotheses about note onsets. It uses a small set of rules and two constraints that restrict it to form only valid rhythmic structures. 

\begin{align*}
\label{eq:rules}
D(\textsc{combine}([h_1, h_2])) &\rightarrow D(h_1) D(h_2)\\
D(\textsc{combine}([h_1, h_2, h_3)) &\rightarrow D(h_1) D(h_2) D((h_3)\\
D(h) &\rightarrow \textrm{On}_i\\
D(h) &\rightarrow *
\end{align*}
where $D(\phi)$ is a metrical duration with features $\phi$, $*$ represents a filler duration (this is needed when notes are tied together or when the first note is not the first beat of a measure) [SHOW SOME EXAMPLES HERE], $\textrm{On}_i$ is an onset at index $i$, $h$ is a hypothesis about the rhythmic analysis of the corresponding metrical duration and $\textrm{combine}/2$ and $\textrm{combine}/3$ are functions that take hypotheses and combine them into a new hypothesis.

The two constraints are:
\begin{enumerate}
\item Any set of two or three metrical durations are not allowed to combine if the first one expands directly to an onset and the others do not recursively expand to an onset.
\item Any set of two or three metrical durations is not allowed to combine if none of the recursively contains an onset.
\end{enumerate}

This parser is only constrained by the number of onsets in the input. In order to make it efficient it needs some way of rejecting unlikely hypotheses. The following section will explain this process.


\subsubsection{Hypothesis generation and rejection}

[Rhythm, rhythmic analysis and hypothesis are used interchangeably here. Make some sense out of this]

When a performance is not metronomic we want to find a \textit{sensible} rhythmic structure. [Picture of too detailed versus too simple analyses a la cemgil 2000]

The likelihood of a rhythm given a set of performed onsets is determined by two factors. One is how well the analysis matches the observed onset times and another is likely the rhythm itself is. In other words, we want to find the \textit{posterior} probability $P(A|N)$, where $A$ is a rhythm, and $N$ is a list of note onsets. We can formulate this as a generative model where

\begin{equation}
\label{eq:model}
P(A|N) \propto P(N|A)P(A).
\end{equation}

The posterior probability of a rhythm given a set of performed onsets is proportional to the probability that this rhythm generated the list of onsets, the \textit{likelihood} times the probability of the rhythm itself, the \textit{prior}.

Several authors have suggested that some rhythmic structures are more likely than others. \cite{cemgil2000rhythm} incorporated a notion of rhythmic complexity into their system for music transcription, where the likelihood of a rhythm is inversely proportional to its complexity. Temperley suggests a more thorough description of rhythm likelihood \citep{temperley2010modeling}. In \cite{temperley2009unified} he uses his hierarchical position model in a probabilistic music analysis system. [Explain somewhere why a PCFG captures Temperley's properties of common practice rhythm. If it even does...]. [Honing suggests a few priors somewhere else as well.]

Our hypotheses are represented as subdivision trees. This analysis suggests yet another way of characterising rhythm likelihood, commonly known as a probabilistic context-free grammar(PCFG). 

We will use several priors to evaluate our model. [these priors should be described in detail either here or in the evaluation section]

The likelihood should be a function that measures how well a hypothesis `fits' the observations. The simplest likelihood function is one that assigns zero probability to all hypotheses that do not exactly fit the observations. Such a likelihood would only allow metronomic performances. 

If we want to handle human performances we need to have tolerance for deviations from metronomic timing. In many models [citations], any deviation from metronomic timing is treated as additive noise. Deviations from metronomic timing are penalised using a normal distribution centred around the metronomic onset.

In order to define how our model determines the likelihood of an analysis, we first need to define how a subdivision tree implies metronomic onsets. 


\subsubsection{Algorithm}

Finding the onsets implied by an hypothesis is done in two steps. The first step is a bottom up process where as soon as enough onsets are available, any missing downbeats or upbeats are estimated. The second step is a top down process where an analysis is converted to a list of features.

For the first step, we need to extend our hypothesis representation a little bit. 
An hypothesis is represented as a tree node with a list of beats. The list of beats contains onsets or expected onsets of the downbeat of each of its children. When a duration node is a terminal node the list of beats simply contains the onsets that the node contains.

As soon as a node governs two or more onsets, empty slots are filled in. A hypothesis containing two or more nodes always implies a downbeat. When these hypotheses are combined with other nodes, onsets or ties
The hypothesis combination process works by filling in as follows. A hypothesis can be an onset, a tie or a combination of hypotheses. When a hypothesis governs only one onset and one or more tie, the hypothesis is treated as a \textit{complex onset}. The hypothesis $(*$ $\bullet)$ for example is treated as an onset at relative position $0.5$, the hypothesis $(*$ $(*$ $\bullet))$ is treated as an onset with relative position 0.75.

The goal of the combination process is to get the best possible estimates of where the up and downbeats of a hypothesis are. 
\begin{algorithm}
\caption{Combine hypotheses}
\label{alg:hypotheses}
\begin{algorithmic}
\Function{combine}{$H$}
	\State $d \leftarrow$ length($H$)
	\State onsets = []
	\State complexonsets = []
	\For{$i \leftarrow 0,d$}
		\If{isOnset($H[i]$)}
			\State \textbf{append} ($i, H[i]$) \textbf{to} onsets
		\EndIf
		\If{hasChildren(H[i])}
			\State $d \leftarrow$ length($H[i]$.children)
			\State $p$, complexOnset $\leftarrow H[i]$
			\If{H[$i$].beats[0] $\neq$ \textit{Null}}
			\Comment{Check if the hypothesis suggests a downbeat}
				\State \textbf{append} ($i, H[i$].beats[0]) \textbf{to} onsets
			\Else
				\State \textbf{append} ($i + p$, complexOnset) \textbf{to} complexonsets
			\EndIf
		\EndIf
	\EndFor
	\If{length(onsets) <= 1}
		\State \textbf{append} complexOnsets \textbf{to} onsets
	\EndIf
	\State beats $\leftarrow$ \Call{fill}{onsets, $d$}
	\State children = $H[:]$
	\State $h \leftarrow$ children, (onsets$[0][0]/d$, onsets$[0][1]$), beats
	\State \textbf{return} $h$
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Fill beat matrix}
\label{alg:hypotheses}
\begin{algorithmic}
\Function{fill}{beats}
\EndFunction
\end{algorithmic}
\end{algorithm}

So a hypothesis is a tuple containing its children, a complex onset and its estimated beats.
Every hypothesis also keeps track of the first onset before and after the hypothesis. This is used later to restrict adding ties to the hypothesis.

Getting observations


A rhythmic analysis containing two or more notes makes some sort of prediction about where other onsets are likely to appear. 

The observations function is defined recursively. The basic intuition is that for every duration symbol, the likelihood of the upbeats is calculated given the downbeats of the level above. 

\begin{algorithm}
\caption{Generate observations}
\label{alg:observations}
\begin{algorithmic}
\Function{observations}{$h$, downbeat, nextDownbeat}
	\State childNodes, beats $\leftarrow h$.children
	\If {beats[0] $\neq$ \textit{Null}}
		\State downbeat $\leftarrow$ beats[0]
	\EndIf
	\State $d \leftarrow$ length(childNodes)
	\State $l \leftarrow$ nextDownbeat - downbeat
	\State obs $\leftarrow$ []
	\If {hasChildren(childNodes[0])}
		\State upbeat $\leftarrow l/d$
		\If{beats[1] $\neq$ \textit{Null}}
			\State upbeat $\leftarrow$ beats[1]
		\EndIf
		\State obs $\leftarrow$ \Call{observations}{childNodes[0], downbeat, upbeat}
	\EndIf
	
	\For {$i \leftarrow 1,d$}
		\If {beats[$i$] $\neq$ \textit{Null}}
			\State \textbf{append} \Call{features}{downbeat, nextDownbeat, beat, $i, d$} \textbf{to} obs
		\EndIf	
		\If {childNodes[$i$] $\neq$ \textit{Null}}
			\State \textbf{append} \Call{observations}{childNode[$i$], $\mathrm{downbeat} + i/d * l$, nextDownbeat} \textbf{to} obs
		\EndIf
	\EndFor
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Calculate the ratio of downbeat length and upbeat length. Other features could be calculated here.}
\label{alg:features}
\begin{algorithmic}
\Function{features}{downbeat, nextDownbeat, beat}
	\State \textbf{return} $\frac{((\mathrm{beat} - \mathrm{downbeat}) / i)}{((\mathrm{nextDownbeat} - \mathrm{beat}) / (d - i))}$
\EndFunction
\end{algorithmic}
\end{algorithm}

Calculating likelihood

We can now calculate the likelihood of any hypothesis by taking the product of the observations that it implies. Optionally we can add an expression parameter that suggests the ratios to be slightly larger than one. The (normalised) likelihood of a set of observations is

\begin{equation}
\label{eq:h_likelihood}
\mathcal{L}(O|h, \mu, \sigma) \propto \prod_{i=0}^N \exp\left(-\frac{(\mu - \log(O_i))^2}{2\sigma^2}\right)
\end{equation}

Where $O$ is a set of down-/upbeat ratios. We expect the down-/upbeat ratios to be close to one and their to be logarithm close to zero. Therefore it makes sense to set $\mu$ to zero. However we may expect downbeats to be slightly stretched and we can set $\mu$ to reflect this.

Rejecting hypotheses

A hypothesis is rejected if the per item likelihood is lower than a certain threshold. The per-observation likelihood is defined as

\begin{equation}
\label{eq:per_obs_likelihood}
\mathcal{L}(O|h, \mu, \sigma) \mbox{ per observation } \propto \exp\left(-\frac{1}{N}\sum_{i=0}^N \frac{(\mu - \log(O_i))^2}{2\sigma^2}\right)
\end{equation}

\subsection{Extra constraints}

Constraints of the corpusparser (a parser that only allows metronomic performances)

Single note analysis constraints

Constraint in adding ties


Introducing triple divisions introduces ambiguities between triple divisions or more complicated constructions of duple divisions (that are quite unlikely).

For this we extend the duration symbol with three optional features. Every symbol now has a vector of onsets or ties. The first item of this vector is defined to be the downbeat, the rest are upbeats. The interval of the downbeat and the first upbeat at level $l$ is the downbeat interval at level $l+1$. This notion is the basis of the model. As soon as a vector contains more than one onset, the vector is filled in with expected onsets given the two onsets.


%Longuet-Higgins used a constant tolerance parameter to determine whether a beat should be subdivided or a rest should be generated. Increased computational power and availability of labelled data now allows us to makes these decisions probabilistic.

%\begin{align*}
%&P(A \rightarrow B, C|O) = P(N|A \rightarrow B, C)P(A \rightarrow B, C)\\
%&P(A \rightarrow b|O) = P(N_i|A \rightarrow b)P(A \rightarrow b)
%\end{align*}

%where A, B, C are arbitrary non-terminal symbols, b is a terminal symbol and O is a set of observations. 

%The priors are given by for example a simple PCFG-like model, below we will only discuss likelihoods. Consider a bottom up chart-parsing algorithm. Such an algorithm would for example consider the (possibility that the first note in the following pattern was generated by the rule $B/4 \rightarrow n$, which is, in this case, correct. 