\abstract{%

An approach is presented here that interprets rhythmic structure of monophonic music performances based on onset times. Rhythmic structure is represented as a subdivision tree. A chart parsing algorithm that uses probabilistic beam search is presented to construct these structures. The probabilistic model is a Bayesian model that is split up in a rhythm model, which estimates the probability of rhythmic structures a priori and an expression model, which estimates the probability that a particular structure generated the observed performance. The parser is completely tempo-independent and does not assume tempo curves. 

It is suggested that local expressive deviations, such as stretching certain beats to emphasise them, can be linked to rhythmic structure and help improve rhythmic parsing performance. The expression model is constructed so that it can potentially capture these local expressive deviations. 

Furthermore, a new corpus containing monophonic performances of well-known jazz standards annotated with rhythmic structure is presented here and used to evaluate the parser.

The performance of the parser with our rhythm and expression model was compared to two other models: a simple expression model that penalises treats expressive deviation as noise and an uninformed rhythm model that ranks every rhythm as equally likely. It was found that while our rhythm model did not perform better than the simple expression model, our rhythm model did perform better than the uninformed model.
}